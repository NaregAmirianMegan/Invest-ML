{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model creation functions\n",
    "def make_dense_nn(scope, n_inputs, n_outputs, h_layer_node_dict, loss_fn, lr=1e-4):\n",
    "    with tf.variable_scope(scope, reuse=tf.AUTO_REUSE):\n",
    "        x = tf.placeholder(tf.float32, [None, n_inputs], name=\"x\")\n",
    "        y = tf.placeholder(tf.float32, [None, n_outputs], name=\"y\")\n",
    "        \n",
    "        prev_layer = x\n",
    "        for layer_name, layer_nodes in h_layer_node_dict.items():\n",
    "            prev_layer = tf.layers.dense(prev_layer, layer_nodes, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(), name=layer_name)\n",
    "        \n",
    "        output = tf.layers.dense(prev_layer, n_outputs)\n",
    "        \n",
    "        loss = tf.reduce_mean(loss_fn(y, output))\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "        \n",
    "        return x, y, output, loss, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct models\n",
    "from_model = {}\n",
    "to_model = {}\n",
    "from_model['x'], from_model['y'], from_model['output'], from_model['loss'], from_model['train_op'] = make_dense_nn(\"from_model\", 2, 1, {'h1': 5}, tf.losses.mean_squared_error)\n",
    "to_model['x'], to_model['y'], to_model['output'], to_model['loss'], to_model['train_op'] = make_dense_nn(\"to_model\", 2, 1, {'h1': 5}, tf.losses.mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constants\n",
    "train_steps = 20000\n",
    "x_batch = np.array([[0, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 0],\n",
    "                    [1, 1]])\n",
    "y_batch = np.array([[0],\n",
    "                    [1],\n",
    "                    [1],\n",
    "                    [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model training\n",
    "def train(model, train_steps, x_batch, y_batch, sess):\n",
    "    for step in range(train_steps):\n",
    "        _, loss = sess.run([model['train_op'], model['loss']], feed_dict={model['x']: x_batch, model['y']: y_batch})\n",
    "        if step % 1000 == 0:\n",
    "            print(\"Loss:\", loss)\n",
    "            print(\"Predictions:\", np.round(sess.run(from_model['output'], feed_dict={from_model['x']: x_batch}), decimals=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3855492\n",
      "Predictions: [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n",
      "Loss: 0.26098192\n",
      "Predictions: [[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: 0.18184265\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Loss: 0.1201729\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 0.07017839\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 0.036435578\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 0.014771845\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 0.0037521082\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 0.00042550123\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 1.070382e-05\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 2.1192344e-08\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 2.4716673e-11\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 8.928969e-12\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 3.0377922e-12\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 1.0582646e-12\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 3.9707126e-13\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 1.2528867e-13\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 4.1855408e-14\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 2.0983215e-14\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Loss: 2.4758e-10\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#train from model, copy weights, and test to model\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#train from model\n",
    "train(from_model, train_steps, x_batch, y_batch, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define copy function\n",
    "def copy_weights(from_model_scope, to_model_scope, sess):\n",
    "    for from_model_var, to_model_var in zip(tf.trainable_variables(from_model_scope), tf.trainable_variables(to_model_scope)):\n",
    "        frm = from_model_var.eval(session=sess)\n",
    "        to = to_model_var.eval(session=sess)\n",
    "        np.copyto(to, frm)\n",
    "        to_model_var.load(to, session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.96147174 -0.8560882   1.0645647   0.2961514   0.84780455]\n",
      " [-0.9614759   0.856066   -0.37036726  0.43776488 -0.84783417]]\n",
      "[-1.0758272e-05 -9.5446167e-06  3.7035573e-01  1.2271113e-01\n",
      " -2.1793145e-05]\n",
      "[[ 0.7830065 ]\n",
      " [ 0.7036456 ]\n",
      " [-0.50691587]\n",
      " [ 0.47948214]\n",
      " [ 0.76059026]]\n",
      "[0.1289014]\n",
      "-------------------------------------\n",
      "[[ 0.35380292 -0.12276626 -0.7714646  -0.6156478   0.4833982 ]\n",
      " [-0.09294921 -0.30254883 -0.21956396  0.63383996  0.00560814]]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[[-0.5980985 ]\n",
      " [-0.0123775 ]\n",
      " [ 0.56791997]\n",
      " [ 0.9893639 ]\n",
      " [-0.1618557 ]]\n",
      "[0.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 0.96147174 -0.8560882   1.0645647   0.2961514   0.84780455]\n",
      " [-0.9614759   0.856066   -0.37036726  0.43776488 -0.84783417]]\n",
      "[-1.0758272e-05 -9.5446167e-06  3.7035573e-01  1.2271113e-01\n",
      " -2.1793145e-05]\n",
      "[[ 0.7830065 ]\n",
      " [ 0.7036456 ]\n",
      " [-0.50691587]\n",
      " [ 0.47948214]\n",
      " [ 0.76059026]]\n",
      "[0.1289014]\n",
      "-------------------------------------\n",
      "[[ 0.96147174 -0.8560882   1.0645647   0.2961514   0.84780455]\n",
      " [-0.9614759   0.856066   -0.37036726  0.43776488 -0.84783417]]\n",
      "[-1.0758272e-05 -9.5446167e-06  3.7035573e-01  1.2271113e-01\n",
      " -2.1793145e-05]\n",
      "[[ 0.7830065 ]\n",
      " [ 0.7036456 ]\n",
      " [-0.50691587]\n",
      " [ 0.47948214]\n",
      " [ 0.76059026]]\n",
      "[0.1289014]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Predictions: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#copy weights test\n",
    "for var in tf.trainable_variables(\"from_model\"):\n",
    "    print(var.eval(session=sess))\n",
    "    \n",
    "print(\"-------------------------------------\")\n",
    "    \n",
    "for var in tf.trainable_variables(\"to_model\"):\n",
    "    print(var.eval(session=sess))\n",
    "    \n",
    "\n",
    "copy_weights(\"from_model\", \"to_model\", sess)\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "#test to model\n",
    "for var in tf.trainable_variables(\"from_model\"):\n",
    "    print(var.eval(session=sess))\n",
    "    \n",
    "print(\"-------------------------------------\")\n",
    "    \n",
    "for var in tf.trainable_variables(\"to_model\"):\n",
    "    print(var.eval(session=sess))\n",
    "    \n",
    "    \n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "print(\"Predictions:\", np.round(sess.run(to_model['output'], feed_dict={to_model['x']: x_batch}), decimals=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
